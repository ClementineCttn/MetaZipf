An accurate description of the spatial distribution of population is important for both theoretical and policy relevant issues, ranging from a better understanding of firms and people localization decisions to the implementation of national and regional policies. Therefore, an extensive literature has ensued on the identification of the city size distribution. 
Such identification involves proper balancing between the statistical and the theoretical dimensions of the problem. From the statistical standpoint, given a sufficiently large set of parameters, it is possible to find a statistical distribution that will provide a close approximation of the empirical data. However, this distribution, and its parameters, may lack a plausible interpretation from the economic theory standpoint. For this reason, more “parsimonious” distributions may be preferred at the cost of some degree of statistical approximation, in exchange for theoretical grounding. Therefore, two specific distributions are most accredited in the literature: the Pareto and the log-normal. Disentangling between the two has important theoretical implications. For example, a Pareto distribution implies that cities are the result of agglomeration forces and industry specific productivity shocks. A log-normal distribution, instead, implies that cities grow proportionally and independently from the initial city size and their distribution results from city-wide rather than industry specific shocks (see Gabaix, 1999, for a discussion). 
Traditional empirical studies rely on the relationship between the log-rank and logsize of cities, a regularity known as Zipf law (Zipf, 1949), to look for evidence of a Pareto distribution, or power law. If the data obeys the law, the log rank-log size, or Pareto, coefficient will be equal to one. This coefficient has been given several economic interpretations. According to Singer (1930) it is a measure of inequality in the city distribution and, hence, an indicator of the degree of urbanization and population concentration. Parr (1985) considers it as a measure of metropolitanization and, hence, overall level of development. Brakman, Garretsen, and van Marrewijk (2001) interpret the estimated Pareto coefficient as an indicator of industrialization and agglomeration economies. Mori, Nishikimi, and Smith (2008) propose a link between industries spatial intensity and population intensity. Finally, Reggiani and Nijkamp (2015) interpret the estimated coefficient as an indicator of economic development in terms of the urban structure, intended as a socioeconomic connected network. 
Using the rank-size regression approach, traditional studies tend to conclude in favor of a Pareto distribution with shape parameter equal to one. These studies, however, present two main limitations. First, they usually consider only the upper tail of the data, i.e., the largest cities, with a sample truncation point that is usually arbitrarily chosen. Second, the evidence in favor of a Pareto has to be reconciled with other empirical evidence showing that cities grow proportionally, a phenomenon known as Gibrat’s law (Gibrat, 1931), which should instead imply a log-normal city-size distribution. Both points are highlighted by Eeckhout (2004) who suggests that the distribution of all cities, rather than just the upper tail, should be considered. He argues that city growth does not depend on the initial city size, providing evidence in favor of Gibrat’s law and that the estimated OLS coefficient of the rank-size rule varies depending on the truncation city size. Eeckhout concludes that the size distribution of all cities follows a log-normal, rather than a Pareto. 
This conclusion, however, has sparked some controversy. Using the same data of Eeckhout (2004), Levy (2009) presents a log-log plot of rank and city size and argues that the distribution of city size can be divided into two parts: a power law in the upper part and a log-normal in the bottom and middle parts. In his reply, Eeckhout (2009) does acknowledge the difficulty of discriminating between a Pareto upper tail and the tail of a log-normal and hints at what may turn out to be a critical, and yet overlooked, point in the literature: “With all the data available, and given that one nonetheless does not want to use all data, the question arises what the appropriate truncation point is. The choice of the truncation point becomes endogenous and can be chosen subjectively to favor one hypothesis over another,” Eeckhout (2009, p. 1682). Hence, a particular distribution may be favored in empirical studies depending on the chosen truncation point with important implications for the theoretical and policy debate. 
The recent literature has developed alternative tests of the best-fitting distribution, which allow further investigation of the truncation point. For example, Clauset, Shalizi, and Newman (2009) (CSN, henceforth) suggest a Kolmogorov-Smirnov test to compare the relative fitness of the data to the Pareto or alternative distributions, including the log-normal. Malevergne, Pisarenko, and Sornette (2011) develop the so-called uniformly most powerful unbiased test (UMPU, henceforth), i.e., a log-likelihood ratio test of the hypothesis that the (log of the) data comes from an exponential distribution against the alternative that the (log of the) true distribution is a truncated normal. Bee, Riccaboni, and Schiavo (2011, 2013) provide a method based on the maximization of the Shannon information entropy under a given number of moment constraints. The above methods rely on some form of recursive approach that can directly or indirectly allow estimating the switching or truncation point for a power law. Ioannides and Skouras (2013) suggest a further nonrecursive test based on maximum likelihood estimation over a composite distribution, i.e., a distribution with a log-normal “body” and a Pareto “tail” that also allows determining the switching point between the two distributions. 
In this paper, hence, we exploit the above methods with a specific focus on the identification of the truncation point. Specifically, we first use a recursive Zipf’s law approach to show the sensitivity of the so-called Pareto coefficient to the truncation point. Second, we apply the above mentioned tests to investigate the best-fitting distribution in relation to the truncation point using U.S. Census data for alternative cities definitions, such as census designated places (CDPs) and Metro and Micropolitan Areas (MMAs). While all methods tend to identify an upper Pareto tail and a log-normal body, they report substantially different lengths for such tail. Therefore, in the third part of our analysis, we provide a reassessment of their ability to correctly identify the truncation point by means of simulations. 
The rest of the paper is organized as follows. The next section illustrates the sensitivity of the traditional rank-size regression to the truncation point by means of a recursive approach. Section 3 reviews the four alternative methods to identify the best-fitting distribution and the truncation point and provides the empirical application on U.S. Census data. Section 4 reports the results of the simulation exercise that compares the four approaches in terms of the identification of the truncation point and Section 5 concludes. 
A long tradition of papers underlines the difficulty of discriminating between a Pareto tail and log-normal distribution. This point is illustrated in Figure 1 comparing log-log plots for the upper tail of the first 1,000 most populous cities (panel a) and for the entire distribution (panel b) using the same CDPs data of Eeckhout (2004). While in the first panel a horizontal plot seems to indicate a Pareto, in the second panel a decreasing plot seems to denote the typical signature of a log-normal. 
More formally, a variable P obeys a Pareto distribution if its density function, and cumulative density function, (P), are: 
where q is a positive shape parameter and is the scale parameter or the truncation city size, i.e., the minimum value of population P. The parameter q is also known as the Pareto coefficient and represents a tail index. As mentioned above, in a log-log plot the distribution is represented by a straight line and Zipf’s law satisfies a Pareto law with q = 1. 
According to Clauset et al. (2009), moreover, few phenomena seem to obey the Pareto distribution for all values and, as discussed above, most studies on the city size distribution find that the Pareto distribution is a good representation just for the upper tail, i.e., above a minimum threshold. However, even when a researcher intends to investigate just the upper tail, the choice of may be critical, as a truncation point that is too high (low) may shorten (lengthen) the “right” size of the upper tail biasing tests of the appropriate distribution. 
As a first step in our analysis, we illustrate the problem of the sensitivity of the Pareto coefficient to different truncation points. In order to do so, we estimate the rank-size rule by means of recursive analysis over the distribution of all cities, as first suggested by Eeckhout (2004). 
In order to perform this analysis, following Eeckhout (2004) we use CDPs from the U.S. Census Bureau covering almost all the U.S. population. These are defined as entities (populated areas) with (“incorporated” places) or without (“unincorporated” places) their own municipal government (city, town, village, borough, and so on). Given that a change in the definition of CDP was introduced in the year 2010 extending the number of CDPs from 25,359 to 29,494 we repeat our analysis across both 2000 and 2010. The largest CDP counts 8,008,278 (8,175,133) inhabitants in the year 2000 (2010). Even though they may not coincide with the economically more meaningful definition of city, throughout the paper we consider these “places” as baseline reference unit in order to make our result comparable to those of Eeckhout (2004), Clauset et al. (2009), Malavergne et al. (2011), Bee et al. (2011, 2013), and Ioannides and Skouras (2013). 
However, the choice of reference urban unit is not uncontroversial and some authors have argued that the metropolitan area is the most desirable choice in size distribution studies (Rosen and Resnick, 1980; Gabaix, 1999; Ioannides and Overman, 2003). Hence, to check for sensitivity, recent studies have compared CDPs to Metropolitan Areas (Gonzalez-Val, 2010) or, following Duranton (2007), to Metropolitan and Micropolitan Areas (Ioannides and Skouras, 2013). In line with these studies, we repeat our analysis for MMAs in 2000 and 2010 from the U.S. Census Bureau, that defines them as “geographic entities associated with at least one core of 10,000 or more population, plus adjacent territory that has a high degree of social and economic integration with the core as measured by commuting ties” (Federal Register, 2010, p. 37251). If the core assumes values between 10,000 and 50,000 the unit is a Micro Area, above 50,000 it becomes a Metro Area. Here, we count 929 Metro and Micro Areas. The largest MMA counts 18,944,519 (19,567,410) inhabitants in the year 2000 (2010). 
As mentioned above, we first use a recursive approach to observe the adherence of the data to Zipf’s law for all possible truncation points of the distribution of all cities. As standard in the literature, we estimate the Pareto coefficient using simple rank-size OLS regressions where, following Gabaix and Ibragimov (2011), the rank is shifted by 0.5 to correct for the potential bias in small samples highlighted by Gabaix and Ioannides (2004), so that the estimating equation is: 
where k is a constant and P is the population size. Standard errors are given by. The parameter q and its standard errors are estimated for recursively truncated samples of the city size distribution, starting with the 10 most populated cities and then adding one (less populated) city at the time until, like Eeckhout (2004), we consider all cities. Clearly, in the first observations we are placing greater reliance on the ability of the Gabaix and Ioannides (2004) standard errors to correct for the likely larger small sample bias. 
Collecting the estimates of the Pareto exponent together with the respective 95 percent confidence interval, we can statistically assess the validity of Zipf’s law for each truncated city size distribution. In particular, while the estimated Pareto coefficient should be invariant to the truncation point when the underlying distribution is a Pareto, it should decrease under the log-normal (Eeckhout, 2004). 
Table 1 reports the OLS estimates of Equation (1) for the same six truncation points chosen by Eeckhout (2004). These results are consistent with previous work. The estimated Pareto coefficient seems, indeed, “threshold sensitive”: the “longer” the upper tail, the lower the estimated coefficient.
In Figures 2(a) and (b) we present the full recursive estimates. Figure 2(a) focuses on the largest 1,000 cities to look more closely at the upper tail. The estimated Pareto coefficient displays some degree of fluctuation in the very first observations, probably due to the greater influence of individual observations in the smaller sample, and then stays constant, indicating a potential Pareto distribution. Interestingly, this information is not evident from Table 1, where the rank-size rule emerges as a diminishing threshold process, but the full adherence of the data to Zipf’s law for the upper tail cannot be analyzed. 
What happens if we extend the analysis from the first 1,000 cities to all other cities in the sample? Figure 2(b) shows all the recursive estimates of the Pareto coefficient (and 95 percent confidence intervals) against each possible truncation threshold. The coefficient clearly diminishes (increases) as we include smaller (larger) cities from around 1.5 for the upper tail to around 0.5 for the entire distribution, a result that is contrary to Figure 2(a) and, in the interpretation of Eeckhout, corroborates the evidence of log-normality. Hence, considering both Figures 2(a) and 2(b) the distribution of CDPs shows a Pareto behavior in the upper tail and log-normal in the rest of distribution. These figures confirm how, within the standard rank-size regression setting, picking an arbitrary may (mis)lead the researcher into concluding in favor of a specific distribution. Finally, comparison of the left and right panels shows that results are robust to the use of different census years and are stable over time, with similar patterns and hierarchy. Again, a more precise specification of the medium-small cities in 2010 does not significantly affect the results. 
In Figure 3, we repeat the exercise on MMAs to obtain a comparison between different statistical urban measures. Previous literature on Metropolitan Areas (Gabaix, 1999; Dobkins and Ioannides, 2001; Ioannides and Overman, 2003) shows that these typically follow Zipf’s law in the whole sample. However, once the sample is extended to include Micropolitan Areas, as in Ioannides and Skouras (2013), the distribution seems to be Pareto only beyond a certain threshold. Figure 3 shows that for a large portion of the data the coefficient is not significantly different from one. However, although less evident than for the CDPs, it is still possible to observe a decay with respect to the truncation point. 
The above analysis provides a graphic representation of the behavior of the estimated Pareto coefficient in relation to different truncation points and clearly shows that for both CDPs and MMAs the Zipf coefficient is sensitive to the choice of truncation point. The distribution of cities seems to follow a Pareto for an upper portion of the data, but not over the entire distribution. Overall, the coefficient seems to display the typical decay pattern that according to Eeckhout (2004) should be the typical signature of the lognormal. However, while the above analysis is useful to gauge the adherence of the data to the Zipf’s law (and a Pareto distribution), it is not necessarily a robust testing procedure to discriminate among alternative distributions. In the rest of the paper, we address this issue more explicitly in relation to the truncation point. 
The relationship between best-fitting distributions and truncation point has received more attention in physics and statistics (see, among the others, Mitzenmacher, 2004; Perline, 2005) than in urban studies and economics. For the distribution of city size, Eeckhout (2004) seems to be the first to hint at the issue. More recently Clauset et al. (2009) offer a recursive method to test for the adherence of the data to a Pareto distribution and identify the threshold for the portion of data where a Pareto in not rejected by statistical tests. Malavergne et al. (2011), Bee et al. (2011, 2013) provide alternative recursive methods based on likelihood ratio tests to identify the best-fitting distribution. These papers find evidence in favor of a Pareto for the upper tail and a log-normal for the body of the distribution of cities and identify the switching point between the two distributions. Ioannides and Skouras (2013) fully acknowledge the truncation point problem and propose an alternative nonrecursive approach, where they first fit a composite Pareto-lognormal (hence, increasing the number of estimated parameters) by maximum likelihood and then formulate a test to identify the switching point between the two. In this section, we first provide a brief description of the above methods and then apply them to our data. 
Clauset et al. (2009) suggest testing the equality between the theoretical and empirical density functions using Kolmogorov-Smirnov tests over recursively truncated distributions, i.e., they compute a Kolmogorov-Smirnov (KS, henceforth) goodness of fit test for a Pareto for each possible truncation point of the distribution. Given the empirical cumulative density function for observations of cities populations, is the theoretical cumulative density function of the Pareto distribution, the KS statistic computes the supremum of the absolute value of the set of distances among the two: 
In sum, the estimate is the value of that minimizes the “recursive” Kolmogorov-Smirnov statistics, D. Then, the population level of the city corresponding to the minimum KS statistics is considered as the threshold for a Pareto, i.e., if the minimum KS appears in a subsample with the top 500 cities, then the population of the city with rank 500 will be the level of the population threshold. 
Under the null, the difference between the two is zero, i.e., the sample is drawn from the reference distribution. Rejection of the null, however, should be considered carefully, as the KS test tends to over-reject the null when the sample is large. 
Malavergne et al. (2011) develop the so-called UMPU test. The test, computationally simple, presents some similarities with the CSN. Since the log-size distribution of a Pareto is an exponential and the log-size distribution of a log-normal is a normal, UMPU computes a likelihood ratio test at any point of the distribution aimed at testing for the null that a given (log) sample is distributed as an exponential distribution against the alternative that the (log) sample is distributed as a normal with mean, and standard deviation. Del Castillo and Puig (1999) have shown that the likelihood ratio test in this setting is equal to the clipped sample coefficient of variation, c, such that: 
Given this statistics, the basic idea behind the test is to run the above likelihood ratio test for any point of the distribution and then pick as a threshold for the Pareto upper tail, the city corresponding to the point where the test rejects the null hypothesis of a Pareto distribution. In this regard then, this test may be considered as both a test for best fit, since it directly compares the fit of the Pareto to that of a log-normal, and a test of identification of the truncation point, since it also gives the switching point between the two distributions. 
Bee et al. (2011, 2013) develop the maximum entropy (ME) approach based on the concept of ME distribution. This is derived from the constrained maximization of the Shannon information entropy, W, such that 
Under k moment constraints. Following Bee et al. (2011) the solution of the maximization is given by: 
where, are the Lagrange multipliers and T is the function defining the characterizing moment. More generally, since the log-likelihood function of W is given by, the authors adopt a log-likelihood ratio test with null k = k∗ against alternative k = k∗ + 1, such that: 
Notice that the Pareto distribution comes from a ME distribution with k = 1, while the log-normal derives from a ME distribution with k = 2. Hence, the procedure in our case aims at recursively estimating the ME density and performs a log-likelihood ratio test for. The switching point between the Pareto and the log-normal is given by the last value where the null hypothesis that k = 1 cannot be rejected. Again, this test allows recursively discriminating between a Pareto and a log-normal distribution. The logic behind the test is similar to the one behind the UMPU, but with a different test statistic and it may be considered as both a test of best fit and of truncation point determination. 
Ioannides and Skouras (2013) (IS, henceforth) propose an approach based on maximization of the likelihood function of a composite Pareto-lognormal distribution with density: 
where f is the lognormal density function and g is the Pareto density function kernel, such that:
and where a is a continuity condition for h and b are conditions that ensure that h is a density, such that: 
where is the normal cumulative density function with same and as in f. IS then maximize the likelihood for h, such that: 
The test is substantially different from the others. Instead of directly comparing distributions for each recursive truncation point of the entire distribution, it is based on the study of the distribution as a whole. Indeed, Ioannides and Skouras (2013) argue that the composite Pareto-lognormal distribution fits the data better than a simple lognormal. Hence, even though the approach does not strictly perform a direct comparison between a Pareto and a log-normal, it is particularly useful as a method to determine the switching point between distributions. 
We apply the above four methods on the U.S. Census Data for CDPs and MMAs in the years 2000 and 2010 to investigate the truncation point for the Pareto distribution. Here, for each method, we concentrate on the parameter estimates, significance, threshold city and relative population size as reported in Table 2. A graphical representation of how each test evaluates the fit of alternative theoretical distributions to the real data is provided in Appendix A. 
The results in Table 2 highlight some degree of variability between the estimated truncation points across the different methodologies, also in relation to the adopted city definition and year. For the CDPs, for example, both in terms of city rank and city size CSN and IS seem to identify similarly short thresholds and UMPU and ME similarly long thresholds, for both the 2000 and 2010 definitions. According to the CSN and IS tests, the upper Pareto tail emerges between the 496th and 536th city (with 60,530—57,755 population size) in the year 2000 and between the 695th and 807th (with 55,081–48,716 population size) in the year 2010. According to the UMPU and ME, the upper Pareto tail emerges between the 1,200th and 1,325th city (with 30,736–28189 population sizes) in the year 2000 and 1,050th—1,100th city (with 38,018-36,478 population size) in the year 2010. Interestingly, across years (in spite of the different definition of CDP) the tests seem to identify different truncation points in terms of threshold city rank, but similar points in terms of threshold city size. 
For the MMAs, the results are less variable across method in terms of city rank, but still variable in terms of city size. Here, UMPU predicts the shortest Pareto tail with a threshold at the 306th city in the year 2000 and 298th in the year 2010. CSN, ME, and IS predict longer Pareto tails with thresholds respectively at the 443th, 551st, 624th city in the year 2000 and at the 447th, 511th, and 626th city in the year 2010. Clearly, given the definition of MMA, these city ranks will correspond to quite variable city sizes. Also, given that the definition of MMA has not changed across years, these results are rather stable over time compared to those for the CDPs. A further interesting result from Table 2 is that IS seems to yield the least variability in the predicted city size threshold across the two city definitions of CDP and MMA. Finally, all methods tend to estimate a truncation point beyond what is assumed in traditional studies of Zipf’s Law (i.e., 100,000 inhabitants). 
The above analysis clearly highlights the great variability in the identification of the length of the Pareto upper tail against the log-normal alternative and, in turn, how the identification of the best-fitting distribution is closely related to the identification of the truncation point. Hence, in the next section we concentrate on this issue and provide a comparison of the above methods by means of simulation to assess their ability to correctly predict the truncation point. 
In this section, we assess the ability of the above alternative tests to identify the truncation point via simulation. This approach involves assuming that the data is indeed distributed with a Pareto upper tail and a log-normal body, simulating the data accordingly, with a known truncation point. Then, each testing procedure is applied to distinguish among the two distributions and identify the “true” truncation point. Details of the procedure employed to simulate the distributions are discussed in Appendix B. 
Specifically, we run our simulations to assess the tests in three directions: the length of the Pareto tail, the number of cities and the size of the Pareto coefficient. In the first instance, we simulate a composite distribution with 25,000 observations and consider five possible lengths of the thresholds, LT = 100; 500; 2,500; 5,000. Second, we maintain a fixed threshold at 500 and let the sample size vary, N = 1,000; 2,000; 5,000; 12,500; 25,000. Finally, we simulate a composite distribution of 25,000 observations and consider different possible Pareto coefficients, q = 0.8, 1, 1.3, 1.8. Results for these three simulation exercises are reported in Tables 3–5. Table 3 considers 100 simulated composite samples of 25,000 observations and provides the estimated (average) parameters for each of the four tests (test statistics and relative standard errors, threshold observation and relative population). Similarly, Table 4 presents the corresponding results for different sample sizes and Table 5 for different Pareto coefficients. 
Some interesting points emerge from these tables. First, in Table 3 it can be seen how all tests tend to overestimate the truncation point, except for IS that underestimates it, i.e., reports a smaller Pareto upper tail, when LT = 500; 1,000. This is confirmed in Table 4, where again all tests overestimate the threshold, except for IS that always underestimates it. When the Pareto coefficient is allowed to vary in Table 5, again all tests always tend to overestimate the threshold, except for IS that tends to overestimate for q = 0.8 and moderately underestimate for the other q coefficients. Importantly, however, in all simulation exercises IS seems to show the best ability in predicting of the “true” threshold. 
As discussed previously, the identification of the truncation point should be related to the overall fitness of the distribution. If the real data is truly generated by a composite distribution, for an appropriate set of parameters IS should yield a better fit than a single Pareto or lognormal. Yet, each test provides different estimated thresholds and displays a different degree of accuracy in terms of threshold estimation. Then, it may be interesting to assess the implications of estimating different truncation points for the overall fitness of a Pareto-lognormal distribution. In this respect, while IS directly fits a composite distribution and allows the calculation of a measure of overall fitness, CSN, UMPU and ME are based on a comparison of the Pareto to the log-normal and are not designed to directly estimate the fitness of a composite distribution. To assess the distributional fitness implications of different threshold estimates, we have fitted alternative composite distributions using the set of thresholds identified by each test and for each simulation in Tables 3–5. Tables C.1–C.3 in Appendix C report the root mean square error of these fitted composite distributions. Overall, these results seem to confirm the evidence of Tables 3–5 and the relationship between the identification of the truncation point and the identification of the best-fitting distribution. 
In the empirical literature, the identification of the city size distribution is part of a large controversy with two most likely candidates among the more parsimonious and theoretically grounded competitors: the Pareto and the log-normal. Recently, some commentators have suggested that part of this controversy may be due to the arbitrary choice of truncation of the observed sample from the distribution of all cities. A truncation point that is too high, or too low, may bias tests of the appropriate distribution of the upper tail. Here, we first illustrate the problem by adopting a recursive Zipf’s law approach. The results of this analysis seem to support the claim by Eeckhout (2009) that an arbitrary choice of the cut-off of the distribution may mislead scholars to conclude in favor of one or the other distribution. While the log-normal seems to best fit the entire sample, truncating the distribution may lead to conclude in favor of a Pareto, especially in the upper tail. In light of these results, the typical economic interpretations of the estimated Pareto coefficient are less meaningful without an in depth analysis of the truncation point. Yet, only recently the literature has given further attention to the problem. 
Hence, we investigate the relationship between the fit of a Pareto and a log-normal and the “truncation point.” Specifically, we use data on CDPs and MMAs from the U.S. Census Bureau and employ the methods suggested by Clauset et al. (2009), Malavergne et al. (2011), Bee et al. (2011, 2013) and Ioannides and Skouras (2013) to obtain an estimate of the switching point between the two distributions. 
All tests underline a good fit of the Pareto in the upper tail and a better fit of the log-normal for the body of the distribution. In all cases the Pareto distribution seems to be longer than traditionally postulated by previous studies according to an arbitrary truncation point. However, the length of the estimated upper Pareto tail varies depending on the different methodology and adopted city definition. 
We have then proposed a simulation exercise to assess the ability of each approach to predict the “true” truncation point. We provide evidence that CSN, UMPU, and ME tend to overestimate the threshold. IS tends to moderately underestimate, providing the closest prediction. 
This analysis seems to provide novel methodological insights on the discrimination between alternative city size distributions and the truncation point issue. We are able to provide new and robust empirical evidence in support of the claim of Eeckhout (2009) that the conclusion in favor of the Pareto or log-normal may depend on the truncation point. Similarly, our evidence confirms the difficulty highlighted in part of the literature of distinguishing between the tail of a log-normal and a power law tail for the population distribution of cities and stresses the importance of identifying the truncation threshold. In this respect, a comparison of alternative tests to identify the threshold for the upper tail seems to suggest the procedure of Ioannides and Skouras (2013) as the most accurate. Finally, we find that the so called “upper tail” of the distribution may be considerably longer than what is traditionally postulated; a result that may have interesting implications for the theoretical and policy debate related to the distribution of cities. 

